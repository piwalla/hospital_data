# 산재 약국 크롤링 계획서

## 📋 개요

**목표**: 근로복지공단 공식 산재 지정 약국 정보 페이지에서 약국 데이터를 크롤링하여 Supabase에 저장

**대상 URL**: https://www.comwel.or.kr/comwel/medi/mesc.jsp

**예상 데이터 수**: 정확한 수는 확인 필요 (사이트에 표시되지 않음)

**선택 이유**: 
- ✅ **공식 데이터**: 근로복지공단 공식 사이트로 신뢰도 높음
- ✅ **법적 안정성**: 공공기관 데이터로 크롤링 제한이 덜함
- ⚠️ **구조 복잡**: 검색어 입력 필수, 시도/구군별 검색 필요

---

## 🔍 페이지 구조 분석

### 검색 폼 구조
- **시도 선택**: `#sido_select` (17개 시도: 서울, 세종, 광주, 대구, 대전, 인천, 부산, 울산, 강원, 경기, 경남, 경북, 전남, 전북, 충남, 충북, 제주)
- **구군 선택**: `#gugun_select` (시도 선택 후 동적으로 로드)
- **동 선택**: `#dong_select` (구군 선택 후 동적으로 로드, 선택사항)
- **검색어 입력**: `#cont-search` (필수, `name="search_word"`)
- **검색 버튼**: 폼 내부 버튼
- **폼 제출**: POST 방식으로 `https://www.comwel.or.kr/comwel/srch/srch.jsp`로 제출

### 테이블 구조
- **헤더**: 지사, 의료기관, 소재지, 전화번호
- **데이터 형식**: HTML 테이블
- **페이지네이션**: 확인 필요 (검색 결과 페이지에서 확인)
- **총 데이터 수**: 사이트에 표시되지 않음 (검색 후 확인 필요)

### 검색 제약사항
- ⚠️ **검색어 필수**: 검색어 없이 검색 불가 ("검색어를 입력해주세요" 알림)
- ⚠️ **특수문자 불가**: 특수문자 사용 시 오류 발생
- ✅ **와일드카드 가능 여부**: 확인 필요 (예: "*", "%" 등)

### 샘플 데이터 구조 (예상)
```javascript
{
  지사: "서울지사",
  의료기관: "약국명",
  소재지: "서울시 강남구 테헤란로 123",
  전화번호: "02-1234-5678"
}
```

**참고**: 실제 검색 결과 확인 필요

---

## 🎯 크롤링 전략

### 1. 접근 방법
- **도구**: Node.js + Playwright (브라우저 자동화)
- **이유**: 
  - JavaScript로 동적 로드되는 구군 목록 처리 가능
  - 실제 브라우저 환경에서 실행하여 차단 위험 감소
  - 페이지네이션 자동 처리 용이

### 2. 크롤링 프로세스

#### Step 1: 모든 시도/구군 조합 순회
- 17개 시도 × 평균 15개 구군 = 약 255개 조합
- 각 조합마다 검색 실행

#### Step 2: 검색 실행
- 시도 선택 → 구군 옵션 로드 대기 (2초)
- 구군 선택 → 동 옵션 로드 대기 (2초, 선택사항)
- **검색어 입력**: 
  - 옵션 1: 빈 문자열 또는 공백 (가능 여부 확인 필요)
  - 옵션 2: 와일드카드 문자 (예: "*", "%")
  - 옵션 3: 일반 검색어 (예: "약국", "의료기관")
- 검색 버튼 클릭

#### Step 3: 검색 결과 페이지 처리
- 테이블 데이터 파싱 (지사, 의료기관, 소재지, 전화번호)
- 페이지네이션 처리 (다음 페이지가 있으면 계속)

#### Step 4: 데이터 수집 및 저장
- 각 조합별 결과를 CSV 파일로 저장
- 중복 제거 (이름 + 주소 기준)
- CSV 파일을 Supabase Import API로 전달

---

## 📊 예상 작업량

### 검색 조합 수
- 시도 수: 17개
- 평균 구군 수: 약 15개 (시도별 상이)
- 예상 총 조합: 약 200-300개

### 소요 시간
- 시도 선택 후 구군 로드 대기: 2초
- 구군 선택 후 동 로드 대기: 2초 (선택사항)
- 검색 실행 및 결과 로드: 3초
- 페이지네이션 처리: 페이지당 2초
- **조합당 평균**: 약 7-10초
- **총 예상 시간**: 약 2-3시간 (200-300개 조합 × 7-10초)
  - 페이지네이션이 많은 경우 추가 시간 필요

---

## 🛠️ 구현 계획

### 파일 구조
```
scripts/
  crawl-pharmacies.js          # 메인 크롤링 스크립트
  test-pharmacy-crawl.js        # 테스트용 (소수 데이터만)
app/api/
  pharmacies/
    import-crawled/route.ts     # 크롤링 데이터 Import API
```

### 주요 기능

#### 1. 크롤링 스크립트 (`crawl-pharmacies-comwel.js`)
```javascript
// 주요 기능:
- Playwright로 브라우저 자동화
- 17개 시도 순회
- 각 시도별 구군 목록 동적 로드
- 구군별 검색 실행 (검색어 전략 필요)
- 테이블 데이터 파싱
- 페이지네이션 처리
- CSV 파일로 저장 (중간 저장)
- 진행 상황 로깅 (시도/구군/페이지)
- 에러 처리 및 재시도
- 중복 제거 (이름 + 주소 기준)
```

#### 2. Import API (`app/api/pharmacies/import-crawled/route.ts`)
```typescript
// 주요 기능:
- CSV 파일 읽기
- 데이터 검증 및 정규화
- Supabase에 저장
- 중복 체크 (이름 + 주소)
- Geocoding은 별도 프로세스로 처리
```

### 데이터 매핑
```typescript
// 크롤링 데이터 → Supabase 스키마
{
  지사: "서울지사",                          // → branch (선택사항, 저장 여부 결정 필요)
  의료기관: "약국명",                        // → name
  소재지: "서울시 강남구 테헤란로 123",        // → address
  전화번호: "02-1234-5678"                  // → phone
}

// 변환 후:
{
  name: "약국명",
  type: "pharmacy",
  address: "서울시 강남구 테헤란로 123",
  phone: "02-1234-5678",  // 하이픈 유지 또는 제거 결정 필요
  department: null,
  latitude: 0,
  longitude: 0
}
```

---

## ⚠️ 주의사항

### 1. 법적/윤리적 고려
- ✅ robots.txt 확인 완료 (크롤링 제한 없음)
- ⚠️ 이용약관 확인 필요
- ⚠️ 서버 부하 최소화 (딜레이 필수)

### 2. 기술적 고려
- **요청 딜레이**: 2-3초 (서버 부하 방지)
- **에러 처리**: 네트워크 오류, 타임아웃 처리
- **재시도 로직**: 실패한 조합은 재시도
- **중간 저장**: CSV 파일로 주기적 저장 (진행 상황 보존)

### 3. 데이터 품질
- **중복 제거**: 이름 + 주소 기준
- **데이터 검증**: 필수 필드 확인
- **Geocoding**: 별도 배치 프로세스로 처리

---

## 📝 구현 단계

### Phase 1: 검색 전략 테스트
- [ ] 검색어 없이 검색 가능 여부 확인
- [ ] 와일드카드 문자로 전체 검색 가능 여부 확인
- [ ] 시도/구군만 선택하고 검색어를 공백으로 검색 가능 여부 확인
- [ ] 검색 결과 페이지 구조 확인 (테이블, 페이지네이션)
- [ ] 샘플 데이터 수집 (서울 강남구 1개 조합만)

### Phase 2: 전체 크롤링 스크립트
- [ ] 모든 시도 순회 로직
- [ ] 구군 목록 동적 로드 및 대기
- [ ] 검색 실행 (검색어 전략 적용)
- [ ] 테이블 데이터 파싱
- [ ] 페이지네이션 자동 처리
- [ ] 에러 처리 및 재시도
- [ ] 진행 상황 로깅 (시도/구군/페이지)
- [ ] 중복 제거 로직

### Phase 3: Import API 구현
- [ ] CSV 파싱
- [ ] 데이터 검증
- [ ] Supabase 저장
- [ ] 중복 체크

### Phase 4: Geocoding 배치 처리
- [ ] 기존 Geocoding API 재사용
- [ ] 약국 주소 Geocoding
- [ ] 좌표 업데이트

---

## 🔄 크롤링 후 처리

### 1. 데이터 검증
- 총 수집된 약국 수 확인
- 필수 필드 누락 확인
- 중복 데이터 확인

### 2. Geocoding
- 기존 `geocode-batch` API 사용
- 약국 주소 → 위도/경도 변환
- 실패한 주소는 VWorld API로 재시도

### 3. 데이터 통합
- 기존 병원 데이터와 통합
- `type` 필드로 구분 (hospital vs pharmacy)

---

## 📈 예상 결과

### 데이터 구조
```sql
-- Supabase hospitals_pharmacies 테이블
{
  id: UUID,
  name: "약국명",
  type: "pharmacy",
  address: "주소",
  phone: "전화번호",
  department: null,
  latitude: 0 (Geocoding 후 업데이트),
  longitude: 0 (Geocoding 후 업데이트),
  last_updated: TIMESTAMP
}
```

### 최종 통계
- 예상 약국 수: 확인 필요 (검색 결과 기반)
- Geocoding 성공률: 95% 이상 목표
- 총 처리 시간: 약 4-5시간 (크롤링 2-3시간 + Geocoding 1-2시간)

---

## 🚀 다음 단계

1. **테스트 크롤링 스크립트 작성** (서울 1-2개 구만)
2. **전체 크롤링 스크립트 작성**
3. **Import API 구현**
4. **실제 크롤링 실행**
5. **Geocoding 배치 처리**
6. **데이터 검증 및 통합**

---

**작성일**: 2025-01-14  
**대상**: 근로복지공단 공식 산재 지정 약국 정보  
**예상 완료일**: 크롤링 2-3시간 + Geocoding 1-2시간 = 총 4-5시간

---

## ⚠️ 크롤링 전 확인 사항

### 1. 검색어 전략 결정 필요
- 검색어 없이 검색 가능한지 확인
- 와일드카드 문자 사용 가능 여부 확인
- 공백 문자로 검색 가능 여부 확인

### 2. 대안 사이트 고려
- **메디서비스 (medisvc.com)**: 
  - 장점: 검색 불필요, 전체 목록 제공, 구조 단순
  - 단점: 공식 데이터 아님, 데이터 수 22,496개
- **근로복지공단 (comwel.or.kr)**: 
  - 장점: 공식 데이터, 신뢰도 높음
  - 단점: 검색어 필수, 구조 복잡, 시간 소요

### 3. 권장 접근 방법
1. **먼저 근로복지공단 테스트**: 검색어 전략 확인
2. **검색어 없이 불가능하면**: 메디서비스 사용 고려
3. **두 사이트 모두 크롤링**: 데이터 교차 검증

### 4. 메디서비스 크롤링 리스크
자세한 리스크 분석은 [MEDISVC_CRAWLING_RISKS.md](./MEDISVC_CRAWLING_RISKS.md) 참고

**주요 리스크 요약**:
- ⚠️ **법적 리스크**: 이용약관 확인 필수
- ⚠️ **데이터 신뢰도**: 공식 데이터와 교차 검증 권장
- ⚠️ **기술적 리스크**: 웹사이트 구조 변경 대비 필요
- ✅ **완화 방안**: 윤리적 크롤링, 정기 업데이트, 다중 데이터 소스

